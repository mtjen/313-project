{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c355d943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/mtjen/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# https://towardsdatascience.com/text-analysis-feature-engineering-with-nlp-502d6ea9225d\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67e1f773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('/Users/mtjen/Desktop/313/project/train.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd2c55e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>cleanedTweets</th>\n",
       "      <th>sentimentText</th>\n",
       "      <th>sentimentVader</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>-0.018750</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>aria_ahrary thetawniest the out of control wil...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>-0.5849</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>m194 0104 utc5km s of volcano hawaii httptcozd...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>police investigating after an ebike collided w...</td>\n",
       "      <td>-0.260417</td>\n",
       "      <td>-0.7845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>the latest more homes razed by northern califo...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  \\\n",
       "0     Our Deeds are the Reason of this #earthquake M...   \n",
       "1                Forest fire near La Ronge Sask. Canada   \n",
       "2     All residents asked to 'shelter in place' are ...   \n",
       "3     13,000 people receive #wildfires evacuation or...   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...   \n",
       "...                                                 ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...   \n",
       "7611  Police investigating after an e-bike collided ...   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...   \n",
       "\n",
       "                                          cleanedTweets  sentimentText  \\\n",
       "0     our deeds are the reason of this earthquake ma...       0.000000   \n",
       "1                 forest fire near la ronge sask canada       0.100000   \n",
       "2     all residents asked to shelter in place are be...      -0.018750   \n",
       "3     13000 people receive wildfires evacuation orde...       0.000000   \n",
       "4     just got sent this photo from ruby alaska as s...       0.000000   \n",
       "...                                                 ...            ...   \n",
       "7608  two giant cranes holding a bridge collapse int...       0.000000   \n",
       "7609  aria_ahrary thetawniest the out of control wil...       0.150000   \n",
       "7610  m194 0104 utc5km s of volcano hawaii httptcozd...       0.000000   \n",
       "7611  police investigating after an ebike collided w...      -0.260417   \n",
       "7612  the latest more homes razed by northern califo...       0.500000   \n",
       "\n",
       "      sentimentVader  target  \n",
       "0             0.2732       1  \n",
       "1            -0.3400       1  \n",
       "2            -0.2960       1  \n",
       "3             0.0000       1  \n",
       "4             0.0000       1  \n",
       "...              ...     ...  \n",
       "7608         -0.4939       1  \n",
       "7609         -0.5849       1  \n",
       "7610          0.0000       1  \n",
       "7611         -0.7845       1  \n",
       "7612          0.0000       1  \n",
       "\n",
       "[7613 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean tweets\n",
    "cleanedTweets = []\n",
    "\n",
    "for index in range(len(test)):\n",
    "    tweet = train['text'][index]\n",
    "    cleaned = re.sub(r'[^\\w\\s]', '', str(tweet).lower().strip())\n",
    "    cleanedTweets.append(cleaned)\n",
    "    \n",
    "train['cleanedTweets'] = cleanedTweets\n",
    "\n",
    "# textblob sentiment\n",
    "train[\"sentimentText\"] = train['cleanedTweets'].apply(lambda x: \n",
    "                                                      TextBlob(x).sentiment.polarity)\n",
    "\n",
    "# vader sentiment\n",
    "train[\"sentimentVader\"] = train['cleanedTweets'].apply(lambda x: \n",
    "                                                       analyser.polarity_scores(x)['compound'])\n",
    "\n",
    "# move target to end\n",
    "col = train.pop('target')\n",
    "train.insert(len(train.columns), 'target', col)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5d0241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "charsToCheck = {'!', '@', '#', '?', '.', ',', 'http'}\n",
    "vowels = {'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U'}\n",
    "nouns = {'NN', 'NNS', 'NNP', 'NNPS'}\n",
    "verbs = {'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'}\n",
    "adj = {'JJ', 'JJR', 'JJS'}\n",
    "adv = {'RR', 'RBR', 'RBS'}\n",
    "\n",
    "hasLocation = []\n",
    "hasKeyword = []\n",
    "tweetNumberOfChars = []\n",
    "specialCharacters = []\n",
    "numberOfWords = []\n",
    "avgCharsPerWord = []\n",
    "numNumericTweet = []\n",
    "numLettersTweet = []\n",
    "numUpperTweet = []\n",
    "numVowelsTweet = []\n",
    "numConsonantsTweet = []\n",
    "numNouns = []\n",
    "numVerbs = []\n",
    "numPrep = []\n",
    "numAdj = []\n",
    "numAdv = []\n",
    "\n",
    "for index in range(len(train)):\n",
    "    ##### location\n",
    "    location = 0\n",
    "    if pd.isnull(train['location'][index]) == False:\n",
    "            location = 1\n",
    "            \n",
    "    ##### keyword\n",
    "    keyword = 0\n",
    "    if pd.isnull(train['keyword'][index]) == False:\n",
    "            keyword = 1\n",
    "    \n",
    "    ###### tweet\n",
    "    text = train['text'][index]\n",
    "    # number of characters in twets\n",
    "    numCharsTweet = len(text)\n",
    "    \n",
    "    # number of specific special characters in tweet\n",
    "    specialChars = []\n",
    "    for specialChar in charsToCheck:\n",
    "        numSpecialChar = text.count(specialChar)\n",
    "        specialChars.append(numSpecialChar)\n",
    "    \n",
    "    # average characters per word\n",
    "    words = text.split()\n",
    "    lenWords = []\n",
    "    numNumeric = 0\n",
    "    numLetters = 0\n",
    "    numUpper = 0\n",
    "    numVowels = 0\n",
    "    numConsonants = 0\n",
    "    \n",
    "    nounNum = 0\n",
    "    verbNum = 0\n",
    "    prepNum = 0\n",
    "    adjNum = 0\n",
    "    advNum = 0\n",
    "    \n",
    "    ans = nltk.pos_tag(words)\n",
    "    for pair in ans:\n",
    "        wordType = pair[1]\n",
    "        if wordType in nouns:\n",
    "            nounNum += 1\n",
    "        elif wordType in verbs:\n",
    "            verbNum += 1\n",
    "        elif wordType == 'IN':\n",
    "            prepNum += 1\n",
    "        elif wordType in adj:\n",
    "            adjNum += 1\n",
    "        elif wordType in adv:\n",
    "            advNum += 1\n",
    "    \n",
    "    for word in words:\n",
    "        wordLength = len(word)\n",
    "        lenWords.append(wordLength)\n",
    "        \n",
    "        # number of letters/numbers, uppercase, vowels, consonants\n",
    "        for char in word:\n",
    "            if char.isnumeric():\n",
    "                numNumeric += 1\n",
    "            if char.isalpha():\n",
    "                numLetters += 1\n",
    "                if char.isupper():\n",
    "                    numUpper += 1\n",
    "                if char in vowels:\n",
    "                    numVowels += 1\n",
    "                else:\n",
    "                    numConsonants += 1\n",
    "        \n",
    "    wordLengthAvg = np.mean(lenWords)\n",
    "    \n",
    "    # tweets with 1 word\n",
    "    if math.isnan(wordLengthAvg):\n",
    "        wordLengthAvg = 1\n",
    "    \n",
    "    # number of words\n",
    "    numWords = len(words)\n",
    "    \n",
    "    hasLocation.append(location)\n",
    "    hasKeyword.append(keyword)\n",
    "    tweetNumberOfChars.append(numCharsTweet)\n",
    "    specialCharacters.append(specialChars)\n",
    "    numberOfWords.append(numWords)\n",
    "    avgCharsPerWord.append(wordLengthAvg)\n",
    "    numNumericTweet.append(numNumeric)\n",
    "    numLettersTweet.append(numLetters)\n",
    "    numUpperTweet.append(numUpper)\n",
    "    numVowelsTweet.append(numVowels)\n",
    "    numConsonantsTweet.append(numConsonants)\n",
    "    numNouns.append(nounNum)\n",
    "    numVerbs.append(verbNum)\n",
    "    numPrep.append(prepNum)\n",
    "    numAdj.append(adjNum)\n",
    "    numAdv.append(advNum)\n",
    "\n",
    "    \n",
    "# specials\n",
    "numEx = []\n",
    "numAt = []\n",
    "numHash = []\n",
    "numQ = []\n",
    "numPeriod = []\n",
    "numComma = []\n",
    "numLinks = []\n",
    "numPunc = []\n",
    "\n",
    "for tweetCharacters in specialCharacters:\n",
    "    totalPunc = 0\n",
    "    for index in range(len(charsToCheck)):\n",
    "        value = tweetCharacters[index]\n",
    "        totalPunc += value\n",
    "        if index == 0:\n",
    "            numEx.append(value)\n",
    "        elif index == 1:\n",
    "            numAt.append(value)\n",
    "        elif index == 2:\n",
    "            numHash.append(value)\n",
    "        elif index == 3:\n",
    "            numQ.append(value)\n",
    "        elif index == 4:\n",
    "            numPeriod.append(value)\n",
    "        elif index == 5:\n",
    "            numComma.append(value)\n",
    "        elif index == 6:\n",
    "            numLinks.append(value)\n",
    "    numPunc.append(totalPunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c6943ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hasLocation</th>\n",
       "      <th>hasKeyword</th>\n",
       "      <th>tweetNumberOfChars</th>\n",
       "      <th>numberOfWords</th>\n",
       "      <th>numEx</th>\n",
       "      <th>numAt</th>\n",
       "      <th>numHash</th>\n",
       "      <th>numQ</th>\n",
       "      <th>numPeriod</th>\n",
       "      <th>numComma</th>\n",
       "      <th>...</th>\n",
       "      <th>numVowelsTweet</th>\n",
       "      <th>numConsonantsTweet</th>\n",
       "      <th>numNouns</th>\n",
       "      <th>numVerbs</th>\n",
       "      <th>numPrep</th>\n",
       "      <th>numAdj</th>\n",
       "      <th>numAdv</th>\n",
       "      <th>sentimentText</th>\n",
       "      <th>sentimentVader</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.018750</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>-0.5849</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.260417</td>\n",
       "      <td>-0.7845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hasLocation  hasKeyword  tweetNumberOfChars  numberOfWords  numEx  \\\n",
       "0               0           0                  69             13      0   \n",
       "1               0           0                  38              7      1   \n",
       "2               0           0                 133             22      1   \n",
       "3               0           0                  65              8      0   \n",
       "4               0           0                  88             16      0   \n",
       "...           ...         ...                 ...            ...    ...   \n",
       "7608            0           0                  83             11      1   \n",
       "7609            0           0                 125             20      2   \n",
       "7610            0           0                  65              8      3   \n",
       "7611            0           0                 137             19      2   \n",
       "7612            0           0                  94             13      1   \n",
       "\n",
       "      numAt  numHash  numQ  numPeriod  numComma  ...  numVowelsTweet  \\\n",
       "0         0        0     0          0         0  ...              25   \n",
       "1         0        0     0          0         0  ...              13   \n",
       "2         0        0     0          0         0  ...              45   \n",
       "3         0        0     1          0         0  ...              24   \n",
       "4         0        0     0          0         0  ...              25   \n",
       "...     ...      ...   ...        ...       ...  ...             ...   \n",
       "7608      0        0     0          0         1  ...              20   \n",
       "7609      0        0     0          2         0  ...              39   \n",
       "7610      0        1     0          0         1  ...              12   \n",
       "7611      0        0     0          0         0  ...              49   \n",
       "7612      0        0     0          0         1  ...              22   \n",
       "\n",
       "      numConsonantsTweet  numNouns  numVerbs  numPrep  numAdj  numAdv  \\\n",
       "0                     31         6         1        1       0       0   \n",
       "1                     18         6         0        1       0       0   \n",
       "2                     64         8         7        3       1       0   \n",
       "3                     26         5         0        1       1       0   \n",
       "4                     45         6         3        4       0       0   \n",
       "...                  ...       ...       ...      ...     ...     ...   \n",
       "7608                  47         4         2        1       2       0   \n",
       "7609                  62         8         0        4       4       0   \n",
       "7610                  26         7         0        1       0       0   \n",
       "7611                  65        10         1        3       3       0   \n",
       "7612                  51        10         0        1       0       0   \n",
       "\n",
       "      sentimentText  sentimentVader  target  \n",
       "0          0.000000          0.2732       1  \n",
       "1          0.100000         -0.3400       1  \n",
       "2         -0.018750         -0.2960       1  \n",
       "3          0.000000          0.0000       1  \n",
       "4          0.000000          0.0000       1  \n",
       "...             ...             ...     ...  \n",
       "7608       0.000000         -0.4939       1  \n",
       "7609       0.150000         -0.5849       1  \n",
       "7610       0.000000          0.0000       1  \n",
       "7611      -0.260417         -0.7845       1  \n",
       "7612       0.500000          0.0000       1  \n",
       "\n",
       "[7613 rows x 26 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new dataframe\n",
    "colNames = ['hasLocation', 'hasKeyword', 'tweetNumberOfChars', 'numberOfWords', 'numEx', \n",
    "            'numAt', 'numHash', 'numQ', 'numPeriod', 'numComma', 'numLinks', 'numPunc',\n",
    "            'avgCharsPerWord', 'numNumericTweet', 'numLettersTweet', 'numUpperTweet',\n",
    "            'numVowelsTweet', 'numConsonantsTweet', 'numNouns', 'numVerbs', 'numPrep', \n",
    "            'numAdj', 'numAdv']\n",
    "colValues = [hasLocation, hasKeyword, tweetNumberOfChars, numberOfWords, numEx, numAt, \n",
    "             numHash,numQ, numPeriod, numComma, numLinks, numPunc, avgCharsPerWord, \n",
    "             numNumericTweet, numLettersTweet, numUpperTweet, numVowelsTweet, \n",
    "             numConsonantsTweet, numNouns, numVerbs, numPrep, numAdj, numAdv]\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for index in range(len(colNames)):\n",
    "    colName = colNames[index]\n",
    "    colVals = colValues[index]\n",
    "    data[colName] = colVals\n",
    "\n",
    "    \n",
    "data['sentimentText'] = train['sentimentText']\n",
    "data['sentimentVader'] = train['sentimentVader']\n",
    "data['target'] = train['target']\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77a496fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7353906762967827"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split to train and test data\n",
    "trainData = data.sample(frac = 0.8, random_state = 25)\n",
    "testData = data.drop(trainData.index)\n",
    "\n",
    "stopIndex = data.shape[1] - 1\n",
    "\n",
    "trainArray = trainData.values\n",
    "trainX = trainArray[:,0:stopIndex]\n",
    "trainY = trainArray[:,stopIndex]\n",
    "\n",
    "testArray = testData.values\n",
    "testX = testArray[:,0:stopIndex]\n",
    "testY = testArray[:,stopIndex]\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(trainX, trainY)\n",
    "model.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf22c4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
